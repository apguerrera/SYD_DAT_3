{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 3 Lab 1 - Git and Markdown\n",
    "\n",
    "> Great work Adrian!!! I really like your reporting style, very clear and well communicated. The projects listed were excellent. I think you should see how hard it is to get data for your favourite 2 projects and go from there. Well done on the coding section as well - excellent approaches and thinking around why you are doing the exercise.\n",
    "\n",
    "##Homework:\n",
    "\n",
    "#### Setup\n",
    "* Resolve any installation issues before next class.\n",
    "* Make sure you have a github profile and created a repo called \"SYD_DAT_3\"\n",
    "* Clone the class repo (this one!)\n",
    "* Review this [code](../labs/Week 1/00_python_refresher.py) for a recap of some Python basics.\n",
    "\n",
    "#### Communication\n",
    "* Read [Analyzing the Analyzers](http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf) for a useful look at the different types of data scientists. Write down 5 key points you took away from the article\n",
    "* Read about some [Markdown Techniques](http://daringfireball.net/projects/markdown/syntax)\n",
    "* Write a summary of 2 chapters of [The Data Science Handbook](http://www.thedatasciencehandbook.com/) in Markdown and submit a pull request in the Lab Directory\n",
    "\n",
    "#### Programming\n",
    "* Complete the lab from class and the additional Exercise below\n",
    "\n",
    "#### Course Project\n",
    "* Come up with 5 different ideas for your course project. For each one list:\n",
    "  * Overview of your idea\n",
    "  * What data you will use\n",
    "  * What the outcome is that you are trying to achieve\n",
    "  * Any ideas of modelling techniques it may involve\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework1_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Answers\n",
    "\n",
    "### Communication\n",
    "#### Analyzing the Analyzers\n",
    "- It is important to classify yourself and the roles you're after to efficively manage both expectations and job descriptions. \n",
    "- There are 4 broad groups most data scientists can be classified as.\n",
    "- It is important to act as a T-shaped employee, with a broad range of knowledge and an in depth understanding of one or more areas.\n",
    "- Data Scientist are generally T shaped employees with a range of skills and indepth knowledge as shown in the data.\n",
    "- Due to the range of data science skillsets and applicability in various departments, it is reccomended to have data scientists on rotation between various departments.\n",
    "\n",
    "> Glad you picked up on the T shaped employee. It's really important to be a well rounded data scientist.\n",
    "\n",
    "### Data science Textbook\n",
    "#### Chapter 3\n",
    "\n",
    "- Pete Skomoroch\n",
    "\n",
    "Interview with a data scientist who famously built the endorsements engine for skills. He goes on to explain the differences in working with a small company vs building prototypes and production level code with LinkedIn. Insights over how the data science landscape has changed over his career, the need to get up to speed with engineering and learning about the tech stack. He then goes into the growing pains of LinkedIn, the need for communication and his thoughts on the future. \n",
    "\n",
    "> Great summary, do you think LinkedIn does a good job with Data Science?\n",
    "\n",
    "#### Chapter 6 \n",
    "\n",
    "- Clare Corthell\n",
    "\n",
    "Started working for a young product development company and decided to teach herself data science over a 6 month course. That course then became the Open SOurce Data Science Masters. Essentially she goes on to promote the value of open source and highlights the nature of market behavior, your current vs future value and the shift from interviews to tryouts. While she is having difficulty having her course legitimised, she reiterates the value in being self taught and how independent learning is a valuable asset  \n",
    "\n",
    "> Did you have a look at the Open data science masters? It's a good overview of resources if you haven't seen it already. Tryouts are a big part of the recruiting process now - take home mini-projects are fairly common and useful for both parties. Independent learning is one of the most important skills you can have - it's a hard field to stay relevant in if you aren't improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Horse Racing Prediction\n",
    "- Analyse past horse racing data to predict future winners.\n",
    "- Use TAB data to collect information on horses age, jockey weight, barrier, past form, blinkers, beaten favourite and current TAB pricing. \n",
    "- Calculate probability of winning and compare it to TAB price for arbitrage\n",
    "- Linear Regression, Machine learning. \n",
    "\n",
    "> I like this if you can source the data. It would be an interesting analysis. See how you go sourcing the data though - it may cost money.\n",
    "\n",
    "## Airbnb Rental Yield\n",
    "- Identify opportunities in the market by comparing differences in Airbnb pricing and seasonality with rental prices\n",
    "- Scrap airbnb and realestate.com.au data, collecting information on availability, price, competition and variances in season and property types\n",
    "- Highlight areas and certain classes of property with the highest rental return.\n",
    "- Classification, linear regression\n",
    "\n",
    "> As I mentioned before - I like this idea. It reminds me a bit of this one [Product Insights for AirBnb](http://blog.echen.me/2015/07/05/product-insights-for-airbnb/). Maybe reach out to this guy and ask how he gathered his data.\n",
    "\n",
    "## Stock Market Analysis\n",
    "- Supervised learning of trends in stock market price relating to news and press releases\n",
    "- Data available from google finance, paired with market updates and sentiment analysis of reports\n",
    "- Observe and measure a correlation between the sentiment of new information and the magnitude of price changes\n",
    "- Classification of news releases, machine learning and regression analysis. \n",
    "\n",
    "> This is a good one too. Text analysis over reports is a good one. What about the early release of reports (like [Twitter's one](http://blogs.wsj.com/digits/2015/04/28/twitters-earnings-report-leaks-on-twitter-an-hour-early/)). There's some good software for backtesting trading strategies you can look at if you are interested. This one will be very difficult to perform though.\n",
    "\n",
    "##  Perfume Selection Algorithm\n",
    "- Able to predict suitable perfumes without smelling first from past perfume useage\n",
    "- Data available from Frangetica.com, an entire database of perfumes and base notes information\n",
    "- Gain insights into customer purchase behavior and predict perfume suggestions based on personal prefference and perfume charaterisitics\n",
    "- Classification / recommendation engine \n",
    "\n",
    "> This is another excellent project. I think you could put togehter a really interesting and practical data science project off this. \n",
    "\n",
    "## Bank Transation Analyser \n",
    "- Analyse your bank transaction data to provide valueble insights into your spending behavior\n",
    "- Personal bank trasation history. Database of trasational data / publicly available data \n",
    "- Able to classify and quantify spending buckets, highlight trends and detect anomalies. \n",
    "- Classification / Machine Learning\n",
    "\n",
    "> Great idea, but getting access to the Bank API's could be a bit tricky. Read up on the T&C's of the API's and see how difficult it will be to get a good feed of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Four - Movie Lens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student          196\n",
       "other            105\n",
       "educator          95\n",
       "administrator     79\n",
       "engineer          67\n",
       "programmer        66\n",
       "librarian         51\n",
       "writer            45\n",
       "executive         32\n",
       "scientist         31\n",
       "artist            28\n",
       "technician        27\n",
       "marketing         26\n",
       "entertainment     18\n",
       "healthcare        16\n",
       "retired           14\n",
       "salesman          12\n",
       "lawyer            12\n",
       "none               9\n",
       "homemaker          7\n",
       "doctor             7\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each occupation in 'users', count the number of occurrences\n",
    "import pandas as pd\n",
    "pd.read_table('u.user')\n",
    "\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('u.user', sep='|', header=None, names=user_cols, index_col='user_id', dtype={'zip_code':str})\n",
    "\n",
    "users.occupation.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "administrator    38.746835\n",
       "artist           31.392857\n",
       "doctor           43.571429\n",
       "educator         42.010526\n",
       "engineer         36.388060\n",
       "entertainment    29.222222\n",
       "executive        38.718750\n",
       "healthcare       41.562500\n",
       "homemaker        32.571429\n",
       "lawyer           36.750000\n",
       "librarian        40.000000\n",
       "marketing        37.615385\n",
       "none             26.555556\n",
       "other            34.523810\n",
       "programmer       33.121212\n",
       "retired          63.071429\n",
       "salesman         35.666667\n",
       "scientist        35.548387\n",
       "student          22.081633\n",
       "technician       33.148148\n",
       "writer           36.311111\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each occupation, calculate the mean age\n",
    "users.groupby(['occupation'])['age'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_age</th>\n",
       "      <th>min_age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>administrator</th>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educator</th>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive</th>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthcare</th>\n",
       "      <td>62</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homemaker</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer</th>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>librarian</th>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>73</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salesman</th>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               max_age  min_age\n",
       "occupation                     \n",
       "administrator       70       21\n",
       "artist              48       19\n",
       "doctor              64       28\n",
       "educator            63       23\n",
       "engineer            70       22\n",
       "entertainment       50       15\n",
       "executive           69       22\n",
       "healthcare          62       22\n",
       "homemaker           50       20\n",
       "lawyer              53       21\n",
       "librarian           69       23\n",
       "marketing           55       24\n",
       "none                55       11\n",
       "other               64       13\n",
       "programmer          63       20\n",
       "retired             73       51\n",
       "salesman            66       18\n",
       "scientist           55       23\n",
       "student             42        7\n",
       "technician          55       21\n",
       "writer              60       18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each occupation, calculate the minimum and maximum ages\n",
    "users.groupby(['occupation'])['age'].agg({'min_age':min,'max_age':max})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation     gender\n",
       "administrator  F         40.638889\n",
       "               M         37.162791\n",
       "artist         F         30.307692\n",
       "               M         32.333333\n",
       "doctor         M         43.571429\n",
       "educator       F         39.115385\n",
       "               M         43.101449\n",
       "engineer       F         29.500000\n",
       "               M         36.600000\n",
       "entertainment  F         31.000000\n",
       "               M         29.000000\n",
       "executive      F         44.000000\n",
       "               M         38.172414\n",
       "healthcare     F         39.818182\n",
       "               M         45.400000\n",
       "homemaker      F         34.166667\n",
       "               M         23.000000\n",
       "lawyer         F         39.500000\n",
       "               M         36.200000\n",
       "librarian      F         40.000000\n",
       "               M         40.000000\n",
       "marketing      F         37.200000\n",
       "               M         37.875000\n",
       "none           F         36.500000\n",
       "               M         18.600000\n",
       "other          F         35.472222\n",
       "               M         34.028986\n",
       "programmer     F         32.166667\n",
       "               M         33.216667\n",
       "retired        F         70.000000\n",
       "               M         62.538462\n",
       "salesman       F         27.000000\n",
       "               M         38.555556\n",
       "scientist      F         28.333333\n",
       "               M         36.321429\n",
       "student        F         20.750000\n",
       "               M         22.669118\n",
       "technician     F         38.000000\n",
       "               M         32.961538\n",
       "writer         F         37.631579\n",
       "               M         35.346154\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each combination of occupation and gender, calculate the mean age\n",
    "\n",
    "users.groupby(['occupation', 'gender'])['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>78390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender  occupation zip_code\n",
       "user_id                                 \n",
       "850       34      M  technician    78390"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample a DataFrame\n",
    "users.sample(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect duplicate users\n",
    "users.duplicated(['age','gender','zip_code']).sum()\n",
    "users.duplicated(['age','gender','occupation', 'zip_code']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
